{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c643a2",
   "metadata": {},
   "source": [
    "\n",
    "# COE241 / COS868 — Projeto (Parte 1) — NDT (Internet)\n",
    "Este notebook automatiza **EDA, MLE e Inferência Bayesiana** para o dataset de testes NDT.\n",
    "\n",
    "> **Arquivos esperados**  \n",
    "> - CSV: `/mnt/data/ndt_tests_tratado.csv` (colunas: `timestamp`, `download_throughput_bps`, `rtt_download_sec`, `upload_throughput_bps`, `rtt_upload_sec`, `packet_loss_percent`, `client`, `server`).\n",
    "> - Saídas: serão salvas em `/mnt/data/ndt_outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "080bb2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>download_throughput_bps</th>\n",
       "      <th>rtt_download_sec</th>\n",
       "      <th>upload_throughput_bps</th>\n",
       "      <th>rtt_upload_sec</th>\n",
       "      <th>packet_loss_percent</th>\n",
       "      <th>client</th>\n",
       "      <th>server</th>\n",
       "      <th>download_throughput_mbps</th>\n",
       "      <th>upload_throughput_mbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01 00:02:31+00:00</td>\n",
       "      <td>1.479141e+07</td>\n",
       "      <td>0.398051</td>\n",
       "      <td>2.468495e+06</td>\n",
       "      <td>0.342112</td>\n",
       "      <td>9.224381</td>\n",
       "      <td>client10</td>\n",
       "      <td>server06</td>\n",
       "      <td>14.791412</td>\n",
       "      <td>2.468495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-01 00:57:47+00:00</td>\n",
       "      <td>2.506106e+07</td>\n",
       "      <td>0.339698</td>\n",
       "      <td>1.577260e+08</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>2.720267</td>\n",
       "      <td>client12</td>\n",
       "      <td>server07</td>\n",
       "      <td>25.061060</td>\n",
       "      <td>157.725964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-01 00:58:15+00:00</td>\n",
       "      <td>7.316323e+08</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.712221e+08</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.896117</td>\n",
       "      <td>client11</td>\n",
       "      <td>server05</td>\n",
       "      <td>731.632346</td>\n",
       "      <td>371.222115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  download_throughput_bps  rtt_download_sec  \\\n",
       "0 2025-08-01 00:02:31+00:00             1.479141e+07          0.398051   \n",
       "1 2025-08-01 00:57:47+00:00             2.506106e+07          0.339698   \n",
       "2 2025-08-01 00:58:15+00:00             7.316323e+08          0.010000   \n",
       "\n",
       "   upload_throughput_bps  rtt_upload_sec  packet_loss_percent    client  \\\n",
       "0           2.468495e+06        0.342112             9.224381  client10   \n",
       "1           1.577260e+08        0.011713             2.720267  client12   \n",
       "2           3.712221e+08        0.014137             0.896117  client11   \n",
       "\n",
       "     server  download_throughput_mbps  upload_throughput_mbps  \n",
       "0  server06                 14.791412                2.468495  \n",
       "1  server07                 25.061060              157.725964  \n",
       "2  server05                731.632346              371.222115  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, sys, math, json, warnings\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_PATH = \"ndt_tests_corrigido.csv\"\n",
    "OUT_DIR = os.path.expanduser(\"~/Desktop/ndt_outputs\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(\"❌ CSV não encontrado:\", DATA_PATH)\n",
    "    print(\"Por favor, suba o arquivo 'ndt_tests_tratado.csv' em /mnt/data e rode novamente.\")\n",
    "    # Criar um CSV de exemplo vazio (schema) para referência\n",
    "    schema_cols = [\"timestamp\",\"download_throughput_bps\",\"rtt_download_sec\",\"upload_throughput_bps\",\"rtt_upload_sec\",\"packet_loss_percent\",\"client\",\"server\"]\n",
    "    pd.DataFrame(columns=schema_cols).to_csv(os.path.join(OUT_DIR,\"schema_example.csv\"), index=False)\n",
    "    raise SystemExit(0)\n",
    "    \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Normaliza nomes de colunas se necessário\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "# Tenta mapear colunas alternativas\n",
    "rename_map = {\n",
    "    'throughput_download_bps':'download_throughput_bps',\n",
    "    'throughput_upload_bps':'upload_throughput_bps',\n",
    "    'rtt_download':'rtt_download_sec',\n",
    "    'rtt_upload':'rtt_upload_sec',\n",
    "    'loss_percent':'packet_loss_percent'\n",
    "}\n",
    "for k,v in rename_map.items():\n",
    "    if k in df.columns and v not in df.columns:\n",
    "        df.rename(columns={k:v}, inplace=True)\n",
    "\n",
    "# --- Filtragem (como a professora pediu) ---\n",
    "cols_to_check = [\n",
    "    'download_throughput_bps',\n",
    "    'upload_throughput_bps',\n",
    "    'rtt_download_sec',\n",
    "    'rtt_upload_sec',\n",
    "    'packet_loss_percent'\n",
    "]\n",
    "\n",
    "# Remove linhas com qualquer valor negativo\n",
    "df = df[(df[cols_to_check] >= 0).all(axis=1)]\n",
    "\n",
    "# Remove linhas com valores NaN\n",
    "df = df.dropna(subset=cols_to_check)\n",
    "\n",
    "\n",
    "# Corrigir valores absurdos (acima de 10^10) dividindo por 1e6 (supõe erro de escala)\n",
    "df.loc[df['download_throughput_bps'] > 1e10, 'download_throughput_bps'] /= 1e6\n",
    "df.loc[df['upload_throughput_bps'] > 1e10, 'upload_throughput_bps'] /= 1e6\n",
    "\n",
    "# Converter para Mbps para graficar\n",
    "df['download_throughput_mbps'] = df['download_throughput_bps'] / 1e6\n",
    "df['upload_throughput_mbps'] = df['upload_throughput_bps'] / 1e6\n",
    "\n",
    "# Converte timestamp\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "else:\n",
    "    raise SystemExit(\"❌ Coluna 'timestamp' ausente no CSV.\")\n",
    "\n",
    "# Checagens básicas\n",
    "expected_cols = {'download_throughput_bps','upload_throughput_bps','rtt_download_sec','rtt_upload_sec','packet_loss_percent','client','server'}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise SystemExit(f\"❌ Colunas ausentes no CSV: {missing}\")\n",
    "\n",
    "# Limpezas simples\n",
    "df = df.dropna(subset=['download_throughput_bps','upload_throughput_bps','rtt_download_sec','rtt_upload_sec','packet_loss_percent','client','server'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2889c",
   "metadata": {},
   "source": [
    "## 1) EDA — estatísticas por cliente e por servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c94d111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gravado: eda_by_client.csv, eda_by_server.csv em /Users/pv/Desktop/ndt_outputs\n"
     ]
    }
   ],
   "source": [
    "metrics = ['download_throughput_bps','upload_throughput_bps',\n",
    "           'rtt_download_sec','rtt_upload_sec','packet_loss_percent']\n",
    "\n",
    "def describe_group(g):\n",
    "    q = g.quantile([0.5,0.9,0.99]).rename(index={0.5:'q50',0.9:'q90',0.99:'q99'})\n",
    "    desc = pd.DataFrame({\n",
    "        'count': g.count(),\n",
    "        'mean': g.mean(),\n",
    "        'median': g.median(),\n",
    "        'var': g.var(ddof=1),   # variância amostral (padrão)\n",
    "        'std': g.std(ddof=1),   # desvio padrão amostral\n",
    "        'min': g.min(),\n",
    "        'max': g.max()\n",
    "    })\n",
    "    return desc.join(q)\n",
    "\n",
    "by_client = df.groupby('client')[metrics].apply(describe_group)\n",
    "by_server = df.groupby('server')[metrics].apply(describe_group)\n",
    "\n",
    "by_client.to_csv(os.path.join(OUT_DIR, 'eda_by_client.csv'))\n",
    "by_server.to_csv(os.path.join(OUT_DIR, 'eda_by_server.csv'))\n",
    "\n",
    "print(\"✅ Gravado: eda_by_client.csv, eda_by_server.csv em\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10996d",
   "metadata": {},
   "source": [
    "### Seleção automática de 2 entidades contrastantes (cliente/servidor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55f44349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes selecionados: ['client06', 'client10']\n",
      "Servidores selecionados: ['server07', 'server05']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(533, 664, 3744, 545)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Critérios simples: escolhe dois clientes com menor e maior mediana de rtt_download_sec\n",
    "client_stats = df.groupby('client')['rtt_download_sec'].median().sort_values()\n",
    "sel_clients = [client_stats.index[0], client_stats.index[-1]] if len(client_stats)>=2 else list(client_stats.index)\n",
    "\n",
    "# Para servidores, mesma lógica\n",
    "server_stats = df.groupby('server')['rtt_download_sec'].median().sort_values()\n",
    "sel_servers = [server_stats.index[0], server_stats.index[-1]] if len(server_stats)>=2 else list(server_stats.index)\n",
    "\n",
    "print(\"Clientes selecionados:\", sel_clients)\n",
    "print(\"Servidores selecionados:\", sel_servers)\n",
    "\n",
    "# Dados filtrados\n",
    "df_c1 = df[df.client==sel_clients[0]]\n",
    "df_c2 = df[df.client==sel_clients[-1]]\n",
    "df_s1 = df[df.server==sel_servers[0]]\n",
    "df_s2 = df[df.server==sel_servers[-1]]\n",
    "\n",
    "len(df_c1), len(df_c2), len(df_s1), len(df_s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43220a1c",
   "metadata": {},
   "source": [
    "### Plots (hist, boxplot, scatter) — salvos em `/mnt/data/ndt_outputs/plots_*.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53d176f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados corrigidos e normalizados (valores em Mbps).\n",
      "✅ Gráficos salvos em /Users/pv/Desktop/ndt_outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_hist(series, title, fname):\n",
    "    plt.figure()\n",
    "    plt.hist(series.dropna(), bins=40, density=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(series.name)\n",
    "    plt.ylabel('density')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, fname))\n",
    "    plt.close()\n",
    "\n",
    "def save_box(series_a, series_b, labels, title, fname):\n",
    "    plt.figure()\n",
    "    plt.boxplot([series_a.dropna(), series_b.dropna()], labels=labels, vert=True)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, fname))\n",
    "    plt.close()\n",
    "\n",
    "def save_scatter(x, y, title, fname):\n",
    "    plt.figure()\n",
    "    plt.scatter(x, y, s=10, alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x.name)\n",
    "    plt.ylabel(y.name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, fname))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Corrigir valores absurdos de throughput (erro de notação científica)\n",
    "df.loc[df['download_throughput_bps'] > 1e10, 'download_throughput_bps'] /= 1e6\n",
    "df.loc[df['upload_throughput_bps'] > 1e10, 'upload_throughput_bps'] /= 1e6\n",
    "\n",
    "# Criar colunas convertidas para Mbps (valores reais para gráficos)\n",
    "df['download_throughput_mbps'] = df['download_throughput_bps'] / 1e6\n",
    "df['upload_throughput_mbps'] = df['upload_throughput_bps'] / 1e6\n",
    "\n",
    "# Substituir as métricas antigas pelas novas (caso queira usar as versões corrigidas)\n",
    "metrics = ['download_throughput_mbps', 'upload_throughput_mbps', 'rtt_download_sec', 'rtt_upload_sec', 'packet_loss_percent']\n",
    "\n",
    "print(\"✅ Dados corrigidos e normalizados (valores em Mbps).\")\n",
    "\n",
    "\n",
    "# Exemplos de gráficos para clientes selecionados\n",
    "for m in metrics:\n",
    "    save_hist(df_c1[m], f\"Hist {m} — {sel_clients[0]}\", f\"hist_{m}_{sel_clients[0]}.png\")\n",
    "    save_hist(df_c2[m], f\"Hist {m} — {sel_clients[-1]}\", f\"hist_{m}_{sel_clients[-1]}.png\")\n",
    "    save_box(df_c1[m], df_c2[m], sel_clients, f\"Boxplot {m} — clientes contrastantes\", f\"box_{m}_clients.png\")\n",
    "\n",
    "# Scatter: escolher par relevante (throughput vs RTT)\n",
    "save_scatter(df['download_throughput_bps'], df['rtt_download_sec'], \"Scatter: download_throughput_bps vs rtt_download_sec\", \"scatter_down_vs_rttd.png\")\n",
    "save_scatter(df['upload_throughput_bps'], df['rtt_upload_sec'], \"Scatter: upload_throughput_bps vs rtt_upload_sec\", \"scatter_up_vs_rttu.png\")\n",
    "\n",
    "print(\"✅ Gráficos salvos em\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98682434",
   "metadata": {},
   "source": [
    "## 2) MLE — parametrizações e estimativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93d78536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal RTT download</td>\n",
       "      <td>0.048477</td>\n",
       "      <td>4.606155e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal RTT upload</td>\n",
       "      <td>0.037491</td>\n",
       "      <td>3.735033e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gamma throughput download</td>\n",
       "      <td>1.495950</td>\n",
       "      <td>2.952534e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gamma throughput upload</td>\n",
       "      <td>1.194078</td>\n",
       "      <td>3.157995e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binomial perda (p)</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model    theta1        theta2\n",
       "0        Normal RTT download  0.048477  4.606155e-03\n",
       "1          Normal RTT upload  0.037491  3.735033e-03\n",
       "2  Gamma throughput download  1.495950  2.952534e-09\n",
       "3    Gamma throughput upload  1.194078  3.157995e-09\n",
       "4         Binomial perda (p)  0.019002           NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Utilitários de MLE sem SciPy\n",
    "\n",
    "def mle_normal_params(x):\n",
    "    mu = np.mean(x)\n",
    "    sigma2 = np.mean((x - mu)**2)  # MLE\n",
    "    return mu, sigma2\n",
    "\n",
    "# Digamma e trigamma aproximadas (Abramowitz & Stegun style)\n",
    "def digamma(x):\n",
    "    x = float(x)\n",
    "    result = 0.0\n",
    "    while x < 6.0:\n",
    "        result -= 1.0/x\n",
    "        x += 1.0\n",
    "    f = 1.0/(x*x)\n",
    "    result += math.log(x) - 0.5/x - f*(1.0/12.0 - f*(1.0/120.0 - f*(1.0/252.0)))\n",
    "    return result\n",
    "\n",
    "def trigamma(x):\n",
    "    x = float(x)\n",
    "    result = 0.0\n",
    "    while x < 6.0:\n",
    "        result += 1.0/(x*x)\n",
    "        x += 1.0\n",
    "    f = 1.0/(x*x)\n",
    "    result += 1.0/x + f*(1.0/2.0 + f*(1.0/6.0 - f*(1.0/30.0)))\n",
    "    return result\n",
    "\n",
    "def mle_gamma_k_beta(y, max_iter=50, tol=1e-8):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    y = y[y>0]\n",
    "    n = y.size\n",
    "    if n==0:\n",
    "        return np.nan, np.nan\n",
    "    mean_y = y.mean()\n",
    "    mean_logy = np.mean(np.log(y))\n",
    "    # Inicializa k via método dos momentos\n",
    "    var_y = y.var(ddof=0)\n",
    "    k = (mean_y**2)/var_y if var_y>0 else 1.0\n",
    "    k = max(k, 1e-6)\n",
    "    # Newton-Raphson para resolver: log(k) - digamma(k) = log(mean) - mean(log y)\n",
    "    target = math.log(mean_y) - mean_logy\n",
    "    for _ in range(max_iter):\n",
    "        f = math.log(k) - digamma(k) - target\n",
    "        g = 1.0/k - trigamma(k)\n",
    "        step = f/g\n",
    "        k_new = k - step\n",
    "        if k_new <= 0:\n",
    "            k_new = k/2\n",
    "        if abs(k_new - k) < tol:\n",
    "            k = k_new\n",
    "            break\n",
    "        k = k_new\n",
    "    beta = k / mean_y\n",
    "    return float(k), float(beta)\n",
    "\n",
    "# Estimações\n",
    "mu_rtt_d, s2_rtt_d = mle_normal_params(df['rtt_download_sec'].values)\n",
    "mu_rtt_u, s2_rtt_u = mle_normal_params(df['rtt_upload_sec'].values)\n",
    "\n",
    "k_down, beta_down = mle_gamma_k_beta(df['download_throughput_bps'].values)\n",
    "k_up,   beta_up   = mle_gamma_k_beta(df['upload_throughput_bps'].values)\n",
    "\n",
    "# Para perda: converter percent para contagem com nt=1000\n",
    "NT = 1000\n",
    "x_losses = np.rint((df['packet_loss_percent'].clip(lower=0)/100.0) * NT).astype(int)\n",
    "p_mle = x_losses.sum() / (NT*len(x_losses))  # MLE da Binomial\n",
    "\n",
    "mle_summary = pd.DataFrame({\n",
    "    'model': ['Normal RTT download','Normal RTT upload','Gamma throughput download','Gamma throughput upload','Binomial perda (p)'],\n",
    "    'theta1': [mu_rtt_d, mu_rtt_u, k_down, k_up, p_mle],\n",
    "    'theta2': [s2_rtt_d, s2_rtt_u, beta_down, beta_up, np.nan]\n",
    "})\n",
    "mle_summary.to_csv(os.path.join(OUT_DIR,'mle_summary.csv'), index=False)\n",
    "mle_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79917622",
   "metadata": {},
   "source": [
    "### Diagnósticos de ajuste (hist + densidade via simulação, QQ via simulação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "936f3bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Diagnósticos salvos em /Users/pv/Desktop/ndt_outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "def qq_plot_sim(data, sim_sampler, title, fname, n_sim=2000):\n",
    "    data = np.asarray(data)\n",
    "    data = data[~np.isnan(data)]\n",
    "    if len(data)==0:\n",
    "        return\n",
    "    xq = np.quantile(data, np.linspace(0.01,0.99,99))\n",
    "    sim = sim_sampler(n_sim)\n",
    "    yq = np.quantile(sim, np.linspace(0.01,0.99,99))\n",
    "    plt.figure()\n",
    "    plt.scatter(xq, yq, s=10)\n",
    "    mn, mx = min(xq.min(), yq.min()), max(xq.max(), yq.max())\n",
    "    plt.plot([mn,mx],[mn,mx])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Dados (quantis)\")\n",
    "    plt.ylabel(\"Modelo (quantis)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, fname))\n",
    "    plt.close()\n",
    "\n",
    "def overlay_hist_with_sim(data, sim_sampler, title, fname, bins=40):\n",
    "    data = np.asarray(data)\n",
    "    data = data[~np.isnan(data)]\n",
    "    if len(data)==0:\n",
    "        return\n",
    "    plt.figure()\n",
    "    plt.hist(data, bins=bins, density=True, alpha=0.6, label=\"dados\")\n",
    "    sim = sim_sampler(50000)\n",
    "    plt.hist(sim, bins=bins, density=True, histtype='step', label=\"modelo\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, fname))\n",
    "    plt.close()\n",
    "\n",
    "# RTT download ~ Normal(mu, s2)\n",
    "overlay_hist_with_sim(df['rtt_download_sec'].values, lambda n: rng.normal(mu_rtt_d, math.sqrt(s2_rtt_d), size=n),\n",
    "                      \"RTT download — hist vs sim Normal\", \"diag_hist_rttd.png\")\n",
    "qq_plot_sim(df['rtt_download_sec'].values, lambda n: rng.normal(mu_rtt_d, math.sqrt(s2_rtt_d), size=n),\n",
    "            \"RTT download — QQ Normal (sim)\", \"diag_qq_rttd.png\")\n",
    "\n",
    "# RTT upload ~ Normal\n",
    "overlay_hist_with_sim(df['rtt_upload_sec'].values, lambda n: rng.normal(mu_rtt_u, math.sqrt(s2_rtt_u), size=n),\n",
    "                      \"RTT upload — hist vs sim Normal\", \"diag_hist_rttu.png\")\n",
    "qq_plot_sim(df['rtt_upload_sec'].values, lambda n: rng.normal(mu_rtt_u, math.sqrt(s2_rtt_u), size=n),\n",
    "            \"RTT upload — QQ Normal (sim)\", \"diag_qq_rttu.png\")\n",
    "\n",
    "# Throughput ~ Gamma(k, beta) (rate)\n",
    "overlay_hist_with_sim(df['download_throughput_bps'].values, lambda n: rng.gamma(shape=k_down, scale=1.0/beta_down, size=n),\n",
    "                      \"Throughput download — hist vs sim Gamma\", \"diag_hist_tdown.png\")\n",
    "qq_plot_sim(df['download_throughput_bps'].values, lambda n: rng.gamma(shape=k_down, scale=1.0/beta_down, size=n),\n",
    "            \"Throughput download — QQ Gamma (sim)\", \"diag_qq_tdown.png\")\n",
    "\n",
    "overlay_hist_with_sim(df['upload_throughput_bps'].values, lambda n: rng.gamma(shape=k_up, scale=1.0/beta_up, size=n),\n",
    "                      \"Throughput upload — hist vs sim Gamma\", \"diag_hist_tup.png\")\n",
    "qq_plot_sim(df['upload_throughput_bps'].values, lambda n: rng.gamma(shape=k_up, scale=1.0/beta_up, size=n),\n",
    "            \"Throughput upload — QQ Gamma (sim)\", \"diag_qq_tup.png\")\n",
    "\n",
    "print(\"✅ Diagnósticos salvos em\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1d8ff",
   "metadata": {},
   "source": [
    "## 3) Inferência Bayesiana (priors conjugadas) e preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60b8c097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>pred_mean</th>\n",
       "      <th>pred_var</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTT download</td>\n",
       "      <td>4.982119e-02</td>\n",
       "      <td>4.924732e-03</td>\n",
       "      <td>4.534205e-02</td>\n",
       "      <td>3.851082e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTT upload</td>\n",
       "      <td>3.898611e-02</td>\n",
       "      <td>4.046071e-03</td>\n",
       "      <td>3.400305e-02</td>\n",
       "      <td>2.993802e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loss fraction</td>\n",
       "      <td>2.263700e-02</td>\n",
       "      <td>2.212902e-05</td>\n",
       "      <td>1.051930e-02</td>\n",
       "      <td>4.801272e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Throughput download</td>\n",
       "      <td>4.923608e+08</td>\n",
       "      <td>1.696509e+17</td>\n",
       "      <td>5.400463e+08</td>\n",
       "      <td>1.112477e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Throughput upload</td>\n",
       "      <td>3.671205e+08</td>\n",
       "      <td>1.089246e+17</td>\n",
       "      <td>4.037609e+08</td>\n",
       "      <td>9.809829e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   var     pred_mean      pred_var     test_mean      test_var\n",
       "0         RTT download  4.982119e-02  4.924732e-03  4.534205e-02  3.851082e-03\n",
       "1           RTT upload  3.898611e-02  4.046071e-03  3.400305e-02  2.993802e-03\n",
       "2        Loss fraction  2.263700e-02  2.212902e-05  1.051930e-02  4.801272e-04\n",
       "3  Throughput download  4.923608e+08  1.696509e+17  5.400463e+08  1.112477e+17\n",
       "4    Throughput upload  3.671205e+08  1.089246e+17  4.037609e+08  9.809829e+16"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split 70/30 temporal\n",
    "cut_idx = int(len(df)*0.7)\n",
    "train = df.iloc[:cut_idx].copy()\n",
    "test  = df.iloc[cut_idx:].copy()\n",
    "\n",
    "# --- Normal-Normal (RTT) ---\n",
    "# Prior fraca: mu0 = média de treino; tau0^2 = 10 * s2_mle (variância conhecida = s2_mle)\n",
    "def normal_normal_posterior(train_series):\n",
    "    x = train_series.values\n",
    "    mu0 = float(np.mean(x))\n",
    "    s2  = float(np.mean((x-mu0)**2))  # σ^2 \"conhecida\" ≈ MLE do treino\n",
    "    tau0_2 = 10.0 * s2\n",
    "    n = len(x)\n",
    "    xbar = float(np.mean(x))\n",
    "    tau_n2 = 1.0 / (1.0/tau0_2 + n/s2)\n",
    "    mu_n   = tau_n2 * (mu0/tau0_2 + n*xbar/s2)\n",
    "    return dict(mu0=mu0, s2=s2, tau0_2=tau0_2, mu_n=mu_n, tau_n2=tau_n2)\n",
    "\n",
    "post_rtt_d = normal_normal_posterior(train['rtt_download_sec'])\n",
    "post_rtt_u = normal_normal_posterior(train['rtt_upload_sec'])\n",
    "\n",
    "# preditiva: N(mu_n, s2 + tau_n2)\n",
    "def normal_predictive_stats(post):\n",
    "    mean = post['mu_n']\n",
    "    var  = post['s2'] + post['tau_n2']\n",
    "    return mean, var\n",
    "\n",
    "pred_mu_rtt_d, pred_var_rtt_d = normal_predictive_stats(post_rtt_d)\n",
    "pred_mu_rtt_u, pred_var_rtt_u = normal_predictive_stats(post_rtt_u)\n",
    "\n",
    "# --- Beta-Binomial (perda) ---\n",
    "NT = 1000\n",
    "x_train = np.rint((train['packet_loss_percent'].clip(lower=0)/100.0)*NT).astype(int)\n",
    "a0, b0 = 1.0, 1.0  # uniforme\n",
    "a_n = a0 + x_train.sum()\n",
    "b_n = b0 + NT*len(x_train) - x_train.sum()\n",
    "\n",
    "# Estatísticas preditivas (fração)\n",
    "pred_mean_loss_frac = a_n/(a_n + b_n)\n",
    "pred_var_loss_count = (NT * (a_n*b_n*(a_n + b_n + NT))) / (((a_n + b_n)**2) * (a_n + b_n + 1))\n",
    "pred_var_loss_frac  = pred_var_loss_count / (NT**2)\n",
    "\n",
    "# --- Gamma-Gamma (throughput) ---\n",
    "def gamma_mle_k_beta(x):\n",
    "    return mle_gamma_k_beta(x)\n",
    "\n",
    "def gamma_gamma_posterior(train_series):\n",
    "    y = train_series.values\n",
    "    y = y[y>0]\n",
    "    k_hat, beta_hat = gamma_mle_k_beta(y)\n",
    "    # prior fraca para beta: Gamma(a0,b0)\n",
    "    a0, b0 = 1.0, 1e-6\n",
    "    a_n = a0 + len(y)*k_hat\n",
    "    b_n = b0 + float(y.sum())\n",
    "    return dict(k_hat=k_hat, a_n=a_n, b_n=b_n)\n",
    "\n",
    "post_tdown = gamma_gamma_posterior(train['download_throughput_bps'])\n",
    "post_tup   = gamma_gamma_posterior(train['upload_throughput_bps'])\n",
    "\n",
    "def beta_prime_predictive_stats(k_hat, a_n, b_n):\n",
    "    # média existe se a_n>1; var se a_n>2\n",
    "    mean = (k_hat * b_n) / (a_n - 1) if a_n>1 else np.nan\n",
    "    var  = (k_hat * (k_hat + a_n - 1) * (b_n**2)) / ((a_n - 1)**2 * (a_n - 2)) if a_n>2 else np.nan\n",
    "    return mean, var\n",
    "\n",
    "pred_mean_tdown, pred_var_tdown = beta_prime_predictive_stats(post_tdown['k_hat'], post_tdown['a_n'], post_tdown['b_n'])\n",
    "pred_mean_tup,   pred_var_tup   = beta_prime_predictive_stats(post_tup['k_hat'],   post_tup['a_n'],   post_tup['b_n'])\n",
    "\n",
    "# Avaliação vs teste\n",
    "def eval_pred_vs_test(pred_mean, pred_var, test_series):\n",
    "    m = float(np.mean(test_series))\n",
    "    v = float(np.var(test_series, ddof=0))\n",
    "    return dict(pred_mean=pred_mean, pred_var=pred_var, test_mean=m, test_var=v)\n",
    "\n",
    "eval_rtt_d = eval_pred_vs_test(pred_mu_rtt_d, pred_var_rtt_d, test['rtt_download_sec'])\n",
    "eval_rtt_u = eval_pred_vs_test(pred_mu_rtt_u, pred_var_rtt_u, test['rtt_upload_sec'])\n",
    "\n",
    "test_loss_frac = (np.rint((test['packet_loss_percent'].clip(lower=0)/100.0)*NT)/NT).values\n",
    "eval_loss = eval_pred_vs_test(pred_mean_loss_frac, pred_var_loss_frac, test_loss_frac)\n",
    "\n",
    "eval_tdown = eval_pred_vs_test(pred_mean_tdown, pred_var_tdown, test['download_throughput_bps'])\n",
    "eval_tup   = eval_pred_vs_test(pred_mean_tup,   pred_var_tup,   test['upload_throughput_bps'])\n",
    "\n",
    "bayes_eval = pd.DataFrame([\n",
    "    {'var':'RTT download', **eval_rtt_d},\n",
    "    {'var':'RTT upload', **eval_rtt_u},\n",
    "    {'var':'Loss fraction', **eval_loss},\n",
    "    {'var':'Throughput download', **eval_tdown},\n",
    "    {'var':'Throughput upload', **eval_tup},\n",
    "])\n",
    "bayes_eval.to_csv(os.path.join(OUT_DIR,'bayes_predictive_eval.csv'), index=False)\n",
    "bayes_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a3368",
   "metadata": {},
   "source": [
    "## 4) Comparação MLE vs Bayes (pontuais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f172f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLE</th>\n",
       "      <th>Bayes E[mu|r]</th>\n",
       "      <th>Bayes E[p|r]</th>\n",
       "      <th>Bayes E[beta|r]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RTT download (mu)</th>\n",
       "      <td>4.847744e-02</td>\n",
       "      <td>0.049821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RTT upload (mu)</th>\n",
       "      <td>3.749119e-02</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss p</th>\n",
       "      <td>1.900155e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tput down (beta)</th>\n",
       "      <td>2.952534e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.903605e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tput up (beta)</th>\n",
       "      <td>3.157995e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.372188e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MLE  Bayes E[mu|r]  Bayes E[p|r]  Bayes E[beta|r]\n",
       "RTT download (mu)  4.847744e-02       0.049821           NaN              NaN\n",
       "RTT upload (mu)    3.749119e-02       0.038986           NaN              NaN\n",
       "Loss p             1.900155e-02            NaN      0.022637              NaN\n",
       "Tput down (beta)   2.952534e-09            NaN           NaN     2.903605e-09\n",
       "Tput up (beta)     3.157995e-09            NaN           NaN     3.372188e-09"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "comp = {\n",
    "    'RTT download (mu)': {'MLE': float(np.mean(df['rtt_download_sec'])), 'Bayes E[mu|r]': float(post_rtt_d['mu_n'])},\n",
    "    'RTT upload (mu)':   {'MLE': float(np.mean(df['rtt_upload_sec'])), 'Bayes E[mu|r]': float(post_rtt_u['mu_n'])},\n",
    "    'Loss p':            {'MLE': float((np.rint((df['packet_loss_percent'].clip(lower=0)/100.0)*NT).sum())/(NT*len(df))), 'Bayes E[p|r]': float(a_n/(a_n+b_n))},\n",
    "    'Tput down (beta)':  {'MLE': float(mle_gamma_k_beta(df['download_throughput_bps'].values)[1]), 'Bayes E[beta|r]': float(post_tdown['a_n']/post_tdown['b_n'])},\n",
    "    'Tput up (beta)':    {'MLE': float(mle_gamma_k_beta(df['upload_throughput_bps'].values)[1]),   'Bayes E[beta|r]': float(post_tup['a_n']/post_tup['b_n'])},\n",
    "}\n",
    "comp_df = pd.DataFrame(comp).T\n",
    "comp_df.to_csv(os.path.join(OUT_DIR,'mle_vs_bayes_point_estimates.csv'))\n",
    "comp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28e032",
   "metadata": {},
   "source": [
    "## 5) Exporta um resumo rápido em CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b86d72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDA por cliente': '/Users/pv/Desktop/ndt_outputs/eda_by_client.csv',\n",
       " 'EDA por servidor': '/Users/pv/Desktop/ndt_outputs/eda_by_server.csv',\n",
       " 'MLE resumo': '/Users/pv/Desktop/ndt_outputs/mle_summary.csv',\n",
       " 'Bayes preditiva vs teste': '/Users/pv/Desktop/ndt_outputs/bayes_predictive_eval.csv',\n",
       " 'Comparação MLE vs Bayes': '/Users/pv/Desktop/ndt_outputs/mle_vs_bayes_point_estimates.csv'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summary_paths = {\n",
    "    \"EDA por cliente\": os.path.join(OUT_DIR,'eda_by_client.csv'),\n",
    "    \"EDA por servidor\": os.path.join(OUT_DIR,'eda_by_server.csv'),\n",
    "    \"MLE resumo\": os.path.join(OUT_DIR,'mle_summary.csv'),\n",
    "    \"Bayes preditiva vs teste\": os.path.join(OUT_DIR,'bayes_predictive_eval.csv'),\n",
    "    \"Comparação MLE vs Bayes\": os.path.join(OUT_DIR,'mle_vs_bayes_point_estimates.csv'),\n",
    "}\n",
    "summary_paths\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
